{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCI-UA 9473 Final Assignment\n",
    "\n",
    "Total: 55pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last assignment, you will get to work on each of the learning frameworks that we introduced throughout the course. The assignement is organized in Three main parts.\n",
    "\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n",
    "- Reinforcement Learning \n",
    "\n",
    "The Total (final) grade will be computed according to the following rule \n",
    "\n",
    "\n",
    "\n",
    "__if__ Mean(Assignment1,Assignment2,Assignment3)< Assignment4 \n",
    "\n",
    "    \n",
    "    Total grade = 0.25*Mean(Assignment1+Assignment2+Assignment3) + 0.75*Assignment4\n",
    "    \n",
    "__else if__ Mean(Assignment1,Assignment2,Assignment3)> Assignment4 \n",
    "\n",
    "    \n",
    "    Total grade = 0.75*Mean(Assignment1+Assignment2+Assignment3) + 0.25*Assignment4\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I. Supervised Learning (25pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise I.1.1 Regression tree (5pts)\n",
    "\n",
    "Tree based methods are simple methods that can be used in both regression and classification. The idea is to split the space into regions and then approximate the data by taking the mean of the targets from each region. The approach starts by splitting the space into two regions $R_1$ and $R_2$. Each of the two regions is then itself split into two more regions, $R_{11}$, $R_{12}$ such that $R_{11}\\cup R_{12} = R_{1}$ and $R_{21}$, $R_{22}$ such that $R_{21}\\cup R_{22} = R_{2}$. By proceeding like this, we end up with a model of the form\n",
    "\n",
    "$$f(x) = \\sum_{m=1}^M c_m I(x\\in R_m)$$\n",
    "\n",
    "where $I(x\\in R_m)$ is a function that takes the value $1$ when $x$ belongs to the subregion $R_m$ and $0$ otherwise. \n",
    "\n",
    "if we minimize the sum of squares, one can show that the optimal value for the coefficients $c_m$ is the average of the targets from region $R_m$, i.e. \n",
    "\n",
    "$$\\hat{c}_m = \\frac{1}{N_m}\\sum_{x_i\\in R_m} t_i$$\n",
    "\n",
    "Now finding the optimal region separation is more tricky. For this reason, the algorithm usually relies on some greedy procedure. \n",
    "\n",
    "For a splitting value $s$, Let $R_1(j,s)$ and $R_2(j,s)$ denote the regions we want to get (with respect to the coordinate/feature $j$), i.e. $R_1(j,s) = \\left\\{\\mathbf{x}|x_j\\leq s\\right\\} $ and $R_2(j,s) = \\left\\{\\mathbf{x}|x_j>s\\right\\}$.\n",
    "\n",
    "In order to find the optimal value $s$, we solve the following problem\n",
    "\n",
    "$$\\min_{(j,s)} \\left[\\min_{c_1} \\sum_{\\mathbf{x}_i\\in R_1(j,s)} (t_i - c_1)^2 + \\min_{c_2} \\sum_{\\mathbf{x}_i\\in R_2(s,j)} (t_i - c_2)^2\\right]\\quad (*)$$\n",
    "\n",
    "As explained before, we can take $c_1$ and $c_2$ to be the averages of the targets from each region. To determine the split, for convenience, we can take it to happen at one of the points from the training set, $\\mathbf{s} = \\mathbf{x}_i$ for some $i\\in \\mathcal{D}$. From this computing the optimal splitting for the criterion (*) becomes easier as we are left with computing the value of this criterion for $s = \\mathbf{x}_i$ given by any of the points from the training set. And return the value that achieves the minimum.  \n",
    "\n",
    "Consider the dataset below. Compute the Regression tree for this dataset. You can stop when you reach a certain node size (take it to be $2$ for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "Points1 = loadmat('Points1_ExTree.mat')\n",
    "Points2 = loadmat('Points2_ExTree.mat')\n",
    "Points3 = loadmat('Points3_ExTree.mat')\n",
    "Points4 = loadmat('Points4_ExTree.mat')\n",
    "\n",
    "\n",
    "Points1 = Points1['Points1_ExTree']\n",
    "Points2 = Points2['Points2_ExTree']\n",
    "Points3 = Points3['Points3_ExTree']\n",
    "Points4 = Points4['Points4_ExTree']\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(Points1[:,0], Points1[:,1])\n",
    "plt.scatter(Points2[:,0], Points2[:,1])\n",
    "plt.scatter(Points3[:,0], Points3[:,1])\n",
    "plt.scatter(Points4[:,0], Points4[:,1])\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "target_1 = np.ones(np.shape(Points1)[0])+np.random.normal(0, 0.2, np.shape(Points1)[0])\n",
    "target_2 = 2*np.ones(np.shape(Points2)[0])+np.random.normal(0, 0.2, np.shape(Points2)[0])\n",
    "target_3 = 5*np.ones(np.shape(Points3)[0])+np.random.normal(0, 0.2, np.shape(Points3)[0])\n",
    "target_4 = -3*np.ones(np.shape(Points4)[0])+np.random.normal(0, 0.2, np.shape(Points4)[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sp_Index': 0, 'sp_Value': 0.5408986175115207, 'left': {'sp_Index': 1, 'sp_Value': 0.47956204379562056, 'left': (4.785461825470161, 2), 'right': {'sp_Index': 0, 'sp_Value': 0.7620967741935484, 'left': (5.182841723291186, 1), 'right': (5.331995390208998, 2)}}, 'right': {'sp_Index': 0, 'sp_Value': 0.4602534562211981, 'left': {'sp_Index': 1, 'sp_Value': 0.6197080291970803, 'left': (-3.509460016621807, 1), 'right': {'sp_Index': 0, 'sp_Value': 0.5247695852534562, 'left': (-2.726749465952524, 2), 'right': (-2.995629536128929, 2)}}, 'right': {'sp_Index': 1, 'sp_Value': 0.39781021897810226, 'left': {'sp_Index': 0, 'sp_Value': 0.1284562211981567, 'left': {'sp_Index': 1, 'sp_Value': 0.5408759124087592, 'left': {'sp_Index': 0, 'sp_Value': 0.18836405529953915, 'left': {'sp_Index': 0, 'sp_Value': 0.2574884792626729, 'left': (0.8213184446253656, 2), 'right': (0.7169843987791544, 1)}, 'right': (1.0410615906759861, 1)}, 'right': (1.1616386841031765, 1)}, 'right': (1.2982404418884552, 1)}, 'right': {'sp_Index': 1, 'sp_Value': 0.33649635036496367, 'left': (2.1778395904127352, 1), 'right': {'sp_Index': 0, 'sp_Value': 0.1975806451612903, 'left': (1.9167190248305035, 2), 'right': (1.998788684904833, 1)}}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3584: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "G:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "G:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "Points = np.concatenate((Points1,Points2,Points3,Points4),axis=0)\n",
    "target = np.concatenate((target_1,target_2,target_3,target_4),axis=0)\n",
    "dataset = np.concatenate((Points,target.reshape(target.shape[0],1)),axis=1)\n",
    "\n",
    "def binSplitDataSet(dataSet, feature, value):\n",
    "    \n",
    "    data0 = dataSet[np.nonzero(dataSet[:,feature] > value)[0],:]\n",
    "    data1 = dataSet[np.nonzero(dataSet[:,feature] <= value)[0],:]\n",
    "    return data0,data1\n",
    "\n",
    "def errcal(dataset):\n",
    "    err = np.var(dataset[:,-1])*dataset.shape[0]\n",
    "    return err\n",
    "\n",
    "\n",
    "\n",
    "def chooseBestSplit(dataSet, errType=errcal, stop_size=2):\n",
    "   \n",
    "    \n",
    "    if len(set(dataSet[:,-1].T.tolist())) == 1 or dataSet.shape[0]<=2:\n",
    "        return None, np.mean(dataSet[:,-1]),dataSet.shape[0]\n",
    "    m,n = dataSet.shape\n",
    "    S = errType(dataset)\n",
    "    bestS = float('inf'); bestIndex = 0; bestValue = 0\n",
    "\n",
    "    for featIndex in range(n-1):\n",
    "        for splitVal in set(dataSet[:,featIndex]):\n",
    "            data0, data1 = binSplitDataSet(dataSet, featIndex, splitVal)\n",
    "            newS = errType(data0) + errType(data1)\n",
    "            if newS < bestS: \n",
    "                bestIndex = featIndex\n",
    "                bestValue = splitVal\n",
    "                bestS = newS\n",
    "\n",
    "    data0, data1 = binSplitDataSet(dataSet, bestIndex, bestValue)\n",
    "    return bestIndex,bestValue,dataSet.shape[0]\n",
    "\n",
    "def createTree(dataSet, errType=errcal, stop_size=2):\n",
    "    \n",
    "    feat, val, nodesize = chooseBestSplit(dataSet, errType, stop_size)\n",
    "    if feat == None: return val, nodesize#\n",
    "    retTree = {}\n",
    "    retTree['sp_Index'] = feat\n",
    "    retTree['sp_Value'] = val\n",
    "   \n",
    "    lSet, rSet = binSplitDataSet(dataSet, feat, val)\n",
    "    retTree['left'] = createTree(lSet, errType, stop_size)\n",
    "    retTree['right'] = createTree(rSet,errType, stop_size)\n",
    "    return retTree  \n",
    "reg_tree = createTree(dataset)\n",
    "print(reg_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise I.1.2. Weakest link (5pts)\n",
    "\n",
    "Once we have built a sufficiently deep tree, we are left with determining whether one cannot reduce the depth of this tree (i.e. how coarse the model can be while still achieving sufficient accuracy). A (too) fine model will obviously lead to overfitting. For any tree, we define the set of leaf nodes (i.e. final set of regions) as $M$. We will use this parameter to encode the complexity of the tree. \n",
    "\n",
    "We can define the error that we make with a particular tree by considering the error on each region and summing those error terms across each region. If we let $R_m$ to denote the (average) error induced by region $R_m$, \n",
    "\n",
    "$$Q_m(T) = \\frac{1}{N_m} \\sum_{x_i\\in R_m} (t_i - \\hat{c}_m)^2$$\n",
    "\n",
    "To account for the complexity of the tree, one can also extend this cost into a loss $\\ell(T)$ which penalize complex trees (with a large number of leaf nodes $M$) as\n",
    "\n",
    "$$\\ell(T) = \\sum_{m=1}^M N_m Q_m(T) + \\alpha M$$\n",
    "\n",
    "We can then look for the optimal tree for any particular value of $\\alpha$. \n",
    "\n",
    "The search for the optimal $\\alpha$ and the associated tree is usually done through a procedure known as _weakest link prunning_ which works as follows \n",
    "\n",
    "For any node other than the leaf nodes, we can study how much of an improvement one can get by deleting the subtree located below the node. To do this, we proceed as follows. For any given subtree, we can define the costs $\\tilde{R}(t) = Q(t) + \\alpha$ and $R(T_t) = Q(T_t) + \\alpha|T_t|$. The first one is the cost of the node $t$ (that is the contribution if we removed the whole subtree below $t$) and the second one is the contribution of the term if we were to keep all the leaf of the subtree. For each node in $T_0$, we can look for the $\\alpha$ at which $R(T_t)>R(t)$. In other words, we look for the value $\\alpha$ such that \n",
    "\n",
    "$$Q(t) + \\alpha < Q(T_t) + \\alpha|T_t|$$\n",
    "\n",
    "This is equivalent to looking for the  $\\alpha$ such that $\\alpha>\\frac{Q(t)-Q(T_t)}{|T_t|-t}$. We can do this for every node $t$. The _weakest link_ $t'$ is then the connection for which the $\\alpha(t')$ is the smallest. If there are multiple nodes achieving the same minimum we remove all the sub-branches associated to those nodes. We define the next subtree by removing the sub-branches for _Weakest link_ $t'$. Let us denote that subtree as $T'$. We then repeat the procedure on $T'$, looking for the nodes with smallest $\\alpha$. The procedure generates a sequence of subtrees $T, T', T''$ with associated values $\\alpha_0, \\alpha_1, \\ldots$. \n",
    "\n",
    "Implement _weakest link prunning_ below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def isTree(obj):\n",
    "     # Determine if the input is a tree\n",
    "    return (type(obj).__name__=='dict')\n",
    "def cal_leaf_errcal(tree,data):\n",
    "    if not isTree(tree):return errcal(data),1\n",
    "    lSet, rSet = binSplitDataSet(data, tree['sp_Index'], tree['sp_Value'])\n",
    "    ltree = cal_leaf_errcal(tree['left'],lSet)\n",
    "    rtree = cal_leaf_errcal(tree['right'],rSet)\n",
    "    Q_T = ltree[0]+rtree[0]\n",
    "    num_leaf = ltree[1]+rtree[1]\n",
    "    return Q_T,num_leaf\n",
    "\n",
    "def tree_alp(tree,data):\n",
    "    if not isTree(tree):return float('inf')\n",
    "    Q_t = errcal(data)\n",
    "    tree_info = cal_leaf_errcal(tree,data)\n",
    "    Q_T = tree_info[0]\n",
    "    T_t = tree_info[1]\n",
    "    return (Q_t-Q_T)/(T_t-1)\n",
    "\n",
    "def bfs_min(tree,data):\n",
    "    #Search for the minimum alpha value of the non-leaf nodes in the tree with width first\n",
    "    #Every node is a subtree. This function will return the path of this subtree,this subtree and the alpha value\n",
    "    tree_list = [tree]\n",
    "    path_list = [[]]\n",
    "    min_alpha = float('inf')\n",
    "    while len(tree_list)!=0:\n",
    "        t = tree_list[0]\n",
    "        path = path_list[0]\n",
    "        del tree_list[0]\n",
    "        del path_list[0]\n",
    "        temp_t = tree.copy()\n",
    "        temp_data = data.copy()\n",
    "\n",
    "        for p in path:\n",
    "            ldata, rdata = binSplitDataSet(temp_data, temp_t['sp_Index'], temp_t['sp_Value'])\n",
    "            \n",
    "            if p=='left':\n",
    "                temp_data = ldata\n",
    "                temp_t = temp_t['left']\n",
    "            else:\n",
    "                temp_data = rdata\n",
    "                temp_t = temp_t['right']\n",
    "        alpha = tree_alp(t,temp_data)\n",
    "        if alpha<min_alpha:\n",
    "            min_alpha = alpha\n",
    "            res_path = path\n",
    "            res_t = t\n",
    "\n",
    "        if isTree(t):\n",
    "            tree_list.append(t['left'])\n",
    "            path_list.append(path+['left'])\n",
    "            tree_list.append(t['right'])\n",
    "            path_list.append(path+['right'])\n",
    "    return res_path,res_t,min_alpha\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_node(subTree):\n",
    "    # Given the subtree,return the number of samples in this subTree and the mean of this samples\n",
    "    tree = subTree.copy()\n",
    "    if isTree(tree['left']):tree['left'] = merge_node(tree['left'])\n",
    "    if isTree(tree['right']):tree['right'] = merge_node(tree['right'])\n",
    "    if not isTree(tree['left'])and not isTree(tree['right']):\n",
    "        num = tree['left'][1]+tree['right'][1]\n",
    "        avg = (tree['left'][0]*tree['left'][1]+tree['right'][0]*tree['right'][1])/num  \n",
    "    return avg,num\n",
    "\n",
    "\n",
    "def prune(Tree,path):\n",
    "    #Given the tree and the path of subtree,this function will turn the subtree into a node \n",
    "    tree = Tree.copy()\n",
    "    if len(path)==0:return merge_node(tree)\n",
    "    if len(path)==1:tree[path[0]]=merge_node(tree[path[0]])\n",
    "    if len(path)>1:tree[path[0]] = prune(tree[path[0]],path[1:])\n",
    "    return tree\n",
    "\n",
    "\n",
    "def seq_tree(Tree,data):\n",
    "    #return a tree sequence\n",
    "    tree = Tree.copy()\n",
    "    res = [tree]\n",
    "    alpha = [float('inf')]\n",
    "    while isTree(tree):\n",
    "        subtree_path,sub_tree,min_alpha = bfs_min(tree,data)\n",
    "        tree = prune(tree,subtree_path)\n",
    "        alpha.append(min_alpha)\n",
    "        res.append(tree)\n",
    "    return res,alpha    \n",
    "      \n",
    "seq,alpha = seq_tree(reg_tree,dataset)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise I.1.3. Cross validation (5pts)\n",
    "\n",
    "Given the sequence of subtrees $T_0,T_1, T_2,\\ldots$ and its accompanying sequence of weights $\\alpha_0,\\alpha_1,\\ldots$, one can show that the sequence contains the optimal $\\alpha^*$. To find this $\\alpha^*$, one can use $k$-fold cross validation. \n",
    "\n",
    "Divide the dataset into $K$ bins of size $N/K$. For each of those bins, we will use one bin as our validation/test set and the remaining $K-1$ bins as our training set. \n",
    "\n",
    "1- Using the training set, compute the tree for each of the values of $\\alpha$ obtained above. You don't need to optimize anything as the value on a region is defined as the average of the targets in this region and the number of levels can be set by only retaining those subtrees for which $R_\\alpha(t)>R_{\\alpha}(T_t)$\n",
    "\n",
    "2-Once you have computed all the subtrees, evaluate the prediction error for those subtrees on the set consisting of the remaining $K$ points. The prediction error is just the average target ($c_m$) from the region in which the new points is located minus the true target of this point.\n",
    "\n",
    "And compute the average error as \n",
    "\n",
    "$$E(\\alpha) = \\frac{1}{N}\\sum_{i=1}^N (\\text{prediction}_{T_k(\\alpha)}(\\mathbf{x}_i) - t_i)^2$$\n",
    "\n",
    "where $N$ is the total number of points in the dataset and $\\text{prediction}_{T_k}$ is the prediction obtained on the tree $T_k(\\alpha)$ learned on the set of $N - K$ points to which $\\mathbf{x}_i$ did not belong (i.e. learned without $\\mathbf{x}_i$)\n",
    "\n",
    "\n",
    "Select the $\\alpha$ which gives the smallest error.\n",
    "\n",
    "Take $k$ between $2$ and $4$ and find the optimal $\\alpha$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3584: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "G:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "G:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "import random\n",
    "lenth = dataset.shape[0]\n",
    "testindex=random.sample(range(0, lenth),int(lenth/3))\n",
    "trainindex = []\n",
    "for i in range(0,lenth):\n",
    "    if i not in testindex:\n",
    "        trainindex.append(i)\n",
    "traindata = dataset[trainindex]\n",
    "testdata = dataset[testindex]\n",
    "reg_tree = createTree(traindata)\n",
    "seq_train,alpha_train = seq_tree(reg_tree,traindata)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the optimal αis 67.73200511922114\n"
     ]
    }
   ],
   "source": [
    "def treeForeCast(tree, inData):\n",
    "\n",
    "    # Given a tree , the function return a predicted value for a single data point.\n",
    "    \n",
    "    \n",
    "    if not isTree(tree): return tree[0]\n",
    "    if inData[tree['sp_Index']] > tree['sp_Value']:\n",
    "        if isTree(tree['left']): return treeForeCast(tree['left'], inData)\n",
    "        else: return tree['left'][0]\n",
    "    else:\n",
    "        if isTree(tree['right']): return treeForeCast(tree['right'], inData)\n",
    "        else: return tree['right'][0]\n",
    "def createForeCast(tree, testData):\n",
    "    # Return the predicted value as a vector\n",
    "    m=len(testData)\n",
    "    yHat = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        yHat[i] = treeForeCast(tree, testData[i])\n",
    "    return yHat\n",
    "def error(pre,label):\n",
    "    return np.sum((pre - label)**2)/pre.size\n",
    "min_error = float('inf')\n",
    "\n",
    "for i,train_tree in enumerate(seq_train):\n",
    "    pre = createForeCast(train_tree,testdata)\n",
    "    temp_error = error(pre,testdata[:,-1])\n",
    "    if temp_error<min_error:\n",
    "        min_error = temp_error\n",
    "        opt_index = i\n",
    "print('the optimal αis',alpha_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Exercise I.2. Bias-Variance (10pts)\n",
    "\n",
    "In this exercise, we will study the decomposition of the prediction error into the bias and variance contribution for a simple regression model. For a given learning model, the prediction error can read as\n",
    "\n",
    "$$\\mathbb{E}\\left\\{(f(\\mathbf{x},\\theta)) - t(\\mathbf{x}))^2\\right\\}$$\n",
    "\n",
    "After some calculation, this expression can reduce to\n",
    "\n",
    "$$\\mathbb{E}_D\\left\\{(f_D(\\mathbf{x},\\theta)) - t(\\mathbf{x}))^2\\right\\} = \\left(\\mathbb{E}\\left\\{f_d(\\mathbf{x}, \\theta)\\right\\} - t(\\mathbf{x})\\right)^2 + \\mathbb{E}_D\\left\\{\\left(f_D(\\mathbf{x}; \\theta) - \\mathbb{E}_D\\left\\{f_D(\\mathbf{x}, \\theta)\\right\\}\\right)^2\\right\\}$$\n",
    "\n",
    "In this expression, the first term represents the squared bias (that is how much the choice of the family of models we pick differs is able to capture of the measurements we have on average). In the second term, you can recognize the expression of the variance. This second term captures how much the models vary within a particular family of models when we change the subset $D$ on which we learn the models. \n",
    "\n",
    "\n",
    "In this exercise, we will illustrate this decomposition. for a simple regression model on noisy degree $3$ datasets with model of degrees from $0$ to $5$\n",
    "\n",
    "Consider the noisy dataset below. For the sake of the exercise, we will not change the dataset each time when computing the average, but rather just generate new points by changing the noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-1,1,10)\n",
    "y = x**3 + x**2 + 2*x + 1\n",
    "\n",
    "numTest = 400\n",
    "\n",
    "ynoisy = y +np.random.normal(0,.6,len(x))\n",
    "\n",
    "plt.scatter(x, ynoisy)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent the three terms (bias, variance and Mean Squared Error) code the following steps \n",
    "\n",
    "__1.__ We will write two nested loops. The first one on the maximum degree of the regression model. The second one on the number of experiments. For each experiments we will generate new points as we did above but with a different noise vector. That is re-use a line of the form ynoisy = y +np.random.normal(0,.6,len(x)) for each XP   \n",
    "\n",
    "\n",
    "__2.__ In each experiment, for each maximum degree of the regression model (0,1,..5), generate the polynomial features up to this degree and learn the regression model on the noisy points with the LinearRegression function from scikit (just use the plain simple synthax : LinearRegression(), no need for any argument and fit the model to the noisy points)\n",
    "\n",
    "\n",
    "__3.__ For each experiment keep track of the models you learn by using the points xprediction below and computing the prediction of the model at those points. Store those predictions in a matrix of size num_MaxDegree x numXP\n",
    "\n",
    "\n",
    "__4.__ Compute each of the three terms (bias, variance and Mean squared error = Bias + variance) by using the expressions given above. \n",
    "\n",
    "\n",
    "__5.__ plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-1,1,10)\n",
    "y = x**3 + x**2 + 2*x + 1\n",
    "\n",
    "maxDegree = 5\n",
    "numTest = 400\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "xprediction = np.linspace(-1,1,100)\n",
    "xprediction = xprediction.reshape((-1,1))  \n",
    "\n",
    "\n",
    "    \n",
    "averagePrediction = np.zeros((len(xprediction),maxDegree))  \n",
    "true = np.zeros((len(xprediction),maxDegree))  \n",
    "variance = np.zeros((len(xprediction),maxDegree))  \n",
    "bias = np.zeros((len(xprediction),maxDegree))  \n",
    "\n",
    "for dmax in np.arange(0,maxDegree):\n",
    "    \n",
    "    ynoisy = np.zeros((len(x),numTest))\n",
    "    predictionTesti = np.zeros((len(xprediction),numTest))\n",
    "\n",
    "    clf = LinearRegression()\n",
    "    \n",
    "    for testi in np.arange(0,numTest):\n",
    "\n",
    "        ynoisy[:,testi] = y +np.random.normal(0,.6,len(x))\n",
    "        \n",
    "        \n",
    "        '''put your code here. Generate the polynomial features up to degree dmax and fit the clf model'''\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        x = x.reshape((x.size,1))\n",
    "        quadratic_featurizer = PolynomialFeatures(degree=dmax)\n",
    "        X_train_quadratic = quadratic_featurizer.fit_transform(x)\n",
    "        X_test_quadratic = quadratic_featurizer.transform(xprediction)\n",
    "        \n",
    "        clf.fit(X_train_quadratic,ynoisy[:,testi])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        predictionTesti[:,testi] = clf.predict(X_test_quadratic) # fill in the matrix with the predictions from each model\n",
    "        \n",
    "\n",
    "    averagePrediction[:,dmax] = np.mean(predictionTesti,axis = 1) # Compute the average prediction across the XPs\n",
    "    \n",
    "    \n",
    "    centeredPrediction = predictionTesti - np.expand_dims(averagePrediction[:,dmax],axis=1)\n",
    "    \n",
    "    variance[:,dmax] = np.sum(centeredPrediction**2,axis=1)/(centeredPrediction.shape[1]-1) # Compute the variance by averaging over the XP (see expression above)\n",
    "    quadratic_featurizer = PolynomialFeatures(degree=maxDegree)\n",
    "    X_train_quadratic = quadratic_featurizer.fit_transform(x)\n",
    "    X_test_quadratic = quadratic_featurizer.transform(xprediction)\n",
    "    clf.fit(X_train_quadratic,y)\n",
    "    true[:,dmax] =  clf.predict(X_test_quadratic) # compute the prediction from the noiselss model to get the targets of the points in xprediction\n",
    "    \n",
    "    bias[:,dmax] =  np.sum((predictionTesti - np.expand_dims(true[:,dmax],axis=1))**2,axis=1)/(predictionTesti.shape[1]-1)# Compute the bias by averaging over the XP (see expression above)\n",
    "        \n",
    "\n",
    "'''plot the result using the lines below'''        \n",
    "\n",
    "plt.semilogy(np.arange(0,maxDegree), np.mean(bias,axis=0), label='bias')\n",
    "plt.semilogy(np.arange(0,maxDegree), np.mean(variance,axis=0), label = 'variance')\n",
    "plt.semilogy(np.arange(0,maxDegree), np.mean(bias,axis=0).reshape(-1,1) + np.mean(variance,axis=0).reshape(-1,1), label = 'MSE')\n",
    "\n",
    "plt.legend() \n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desired result :\n",
    "    \n",
    "<img src=\"desiredResultAssign4.png\" width=\"500\" height=\"300\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
